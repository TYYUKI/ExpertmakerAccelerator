\documentclass[a4paper]{report}
\usepackage{graphicx}
\usepackage{color}
%% Replace serif font with (postscript) helvetica
%\usepackage[scaled]{helvet}
\renewcommand*\familydefault{\sfdefault} %% Only if the base font of the document is to be sans serif
\usepackage[T1]{fontenc}
\setlength{\textwidth}{160mm}
\setlength{\oddsidemargin}{0mm}
\setlength{\evensidemargin}{0mm}
\setlength{\textheight}{250mm}
\setlength{\voffset}{-20mm}
%\usepackage{showframe}
\usepackage{xspace}
%\usepackage{pgffor}

%%%  Various reserved words  %%%
%\newcommand{\urd}{\texttt{urd}\xspace}
\newcommand{\joblist}{\texttt{JobList}\xspace}
\newcommand{\jobtuple}{\texttt{JobTuple}\xspace}
%\newcommand{\callmethod}{\texttt{call\_method}\xspace}
%\newcommand{\arecord}{\texttt{a.record}\xspace}
%\newcommand{\automatacommon}{\texttt{automata\_common}\xspace}
%\newcommand{\defaultdict}{\texttt{defaultdict}\xspace}
%\newcommand{\jobid}{\texttt{jobid}\xspace}
\newcommand{\jobids}{\texttt{jobids}\xspace}
\newcommand{\datasets}{\texttt{datasets}\xspace}
\newcommand{\options}{\texttt{options}\xspace}
\newcommand{\prepare}{\texttt{prepare}\xspace}
\newcommand{\analysis}{\texttt{analysis}\xspace}
\newcommand{\synthesis}{\texttt{synthesis}\xspace}
\newcommand{\analysisres}{\texttt{analysis\_res}\xspace}
\newcommand{\prepareres}{\texttt{prepare\_res}\xspace}
\newcommand{\params}{\texttt{params}\xspace}
\newcommand{\jobparams}{\texttt{job\_params}\xspace}
\newcommand{\sliceno}{\texttt{sliceno}\xspace}
% \newcommand{\jobids}{\texttt{jobids}\xspace}

\usepackage{xspace}
%%%  A pretty minted-environment for Python  %%%
\usepackage{minted}
\usemintedstyle{colorful}
\definecolor{bg}{rgb}{0.95,0.95,0.95}
\definecolor{bg_shell}{rgb}{0.95,0.95,1.00}
\newminted[python]{python}{bgcolor=bg, frame=lines}
\newminted[pythonBEG]{python}{bgcolor=bg, frame=topline}
\newminted[pythonMID]{python}{bgcolor=bg}
\newminted[pythonEND]{python}{bgcolor=bg, frame=bottomline}
\newminted[shell]{bash}{bgcolor=bg_shell, frame=lines}

\newcommand{\exempel}[1]{\noindent\textbf{Example: #1}\\}






%\includeonly{urd}

\include{xmtitle}

\begin{document}
\titleLL
\newpage


%\tableofcontents


\section*{Glossary}

% \begin{tabular*}{\textwidth}{l @{\extracolsep{\fill}} l}
\begin{tabular*}{\textwidth}{ll}
method    & main source file of program to be executed by framework\\
package   & a location where methods are stored\\
job       & a running or completed method\\
jobid     & a link to a successfully completed method\\
workdir   & a location where job data and metadata is stored\\
dataset   & efficient storage of data\\
chain     & a one-directional list of datasets\\
urd       & dispatcher and job database\\
automata  & a script run by urd dispatching or recalling jobs\\
\end{tabular*}

--------------------------------------------------------------------------------
Wikitext:

The Accelerator is a platform capable of working at high speed with
billions of lines of data on a single computer.  Data is represented
and accessed with close to zero overhead, and results are
automatically reused.

It has been used in live projects for production and analysis since
2012.

--------------------------------------------------------------------------------

\chapter{Introduction}

The Accelerator is a very efficient environment for running and
scheduling big data tasks.  It is begin developed continuously since
the start in 2012, and has been used in seven different projects, of
which three has been live to customers, and the other four was data
analysis and insight projects.

Due to its minimalistic implementation, the Accelerator is capable of
working at high speed with billions of lines of data on a single
computer.  Two things stand out: first, all jobs are bookkeeped in a
novel way; and second, data is represented and accessed with close to
zero overhead.  The end result is a globally optimised data processing
machine with a wide spectrum of uses.

Some Accelerator features
\begin{itemize}
\item \textbf{Data integration} - The Accelerator has been used in
  several projects with different customers and data, and has thereby
  adopted to a number of formats and cases.
\item \textbf{Efficient Data Access} - Data is streamed through jobs
  using low level operating- and filesystem primitives.
\item \textbf{Simple job tracking} - Easy to find source data, easy to
  use results from other users.
\item \textbf{Transparency} - Total context for all jobs ever run is
  stored and straightforward to retreive.  Any job could be replayed
\end{itemize}





\newpage
Here is a list of some of the background ideas that coloured the work
on the Accelerator.
\begin{itemize}

\item{parallel processing}
  
\item \textbf{Data, recipies (code), and computation} - Data and code
  is more important than computation.  If data integrity is
  maintained, and code version controlled, computation is repeatable
  and can be replicated.

\item \textbf{Never delete or change input data} - What is saved by
  freed storage is nothing compared to the cost of loss of history:
  replication becomes impossible, as well as certain analyses.

\item \textbf{Data should be accessable with minimum overhead}

\item \textbf{Appending columns and rows should have minimal overhead.}

\item \textbf{Live and dev environment is equivalent}
\item \textbf{ blah - analysis and production same blah@@@}
  
\item \textbf{Bookkeep intermediate results.  Use it --- don't recompute!}

\item \textbf{client server configuration}

\item \textbf{simplicity} use basic file systems, and simple,
  minimalistic programs.  (Maintainability, stability, observability,
  and speed).  Adding layers and applications slows things down.

\item \textbf{Moore's law and bottlenecks} CPU, memory size, and disk
  storage increase exponentionally over time for constant price.
  Interconnection speed does not.  Avoid bottlenecks!

\item \textbf{Avoid clusters} Are clusters for speed or redundancy?
  How many machines does a cluster need to have to par a single
  machine with data and code stored locally?
\end{itemize}




\chapter{Overview}
\include{concepts}

\chapter{High Level Control:  Urd}
\include{urd}

\chapter{Method}
\include{method}

\chapter{Dataset}
\include{dataset}

\chapter{Iterator}
\include{iterator}

\chapter{standard methods}
\include{standard_methods}

%\chapter{habitatiii}
%\include{habitatiii}

\end{document}


