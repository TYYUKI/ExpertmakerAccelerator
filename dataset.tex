\section{Dataset properties}

MANY DATASETS PER JOBID

The dataset is the container for fast and simple access to data.  Data
in a dataset are stored as a matrix in rows and columns.

\begin{python}
datasets = ('source',)

def synthesis():
\end{python}

\begin{python}
  print datasets.source.columns.keys()
  # [u'GTIN', u'date', u'locale', u'subsource']

  # each key, i.e. column, has a number of properties, of which the
  # most important ones are shown below
  print datasets.source.columns['locale'].type
  # ascii
  print datasets.source.columns['locale'].name
  # locale
  print datasets.source.columns['locale'].min
  # 3
  print datasets.source.columns['locale'].max
  # 9
  
\end{python}

Will procuce a vector of the number of lines in each slice, like this

\begin{python}
  print datasets.source.lines
  """
[5771L, 6939L, 6212L, 6312L, 6702L, 6341L, 5988L, 6195L,
 6741L, 6587L, 6518L, 5840L, 6327L, 5933L, 6745L, 6673L,
 6536L, 6405L, 6259L, 6455L, 6036L, 6088L, 6937L, 6245L,
 6418L, 6437L, 6360L, 6106L, 6878L]
"""
\end{python}

A tuple of number of columns and total number of lines

\begin{python}
  print datasets.source.shape
  # (4, 184984L)
\end{python}
the second number is exactly the sum of the number of lines for each
slice from above.

other properties are

\begin{python}
  print datasets.source.filename
  """
/data/incoming/raw_repository_5391.gz
"""
\end{python}

\begin{python}
  print datasets.source.caption
  """
flattening
"""
\end{python}


and more

\begin{python}
  print datasets.source.hashlabel
  """
GTIN
"""
\end{python}
\begin{python}
datasets.source.column\_filename
\end{python}

\begin{python}
  print datasets.source.previous
  """
neu4-4893_0/default
"""
\end{python}




\section{Dataset Iterators}

\subsection{iterate}
\begin{python}
# def iterate(self, sliceno, columns=None, hashlabel=None, filters=None, translators=None):
  for item in datasets.source.iterate(sliceno=None, columns=None):
    print item
\end{python}
sliceno=None iterates over all slices.
columns=None iterates over all columns.

\subsection{iterate\_chain}
\begin{python}
# def iterate_chain(self, sliceno, columns=None, length=-1, reverse=False, hashlabel=None, stop_jobid=None, pre_callback=None, post_callback=None, filters=None, translators=None):
\end{python}



\subsection{iterate\_list}
\begin{python}
  # def iterate_list(sliceno, columns, jobids, hashlabel=None, pre_callback=None, post_callback=None, filters=None, translators=None):
  from dataset import Dataset
  for item in Dataset.iterate_list(None, None, datasets.source):
    print item
\end{python}

\subsection{filters and translators}

\subsection{pre and post callback}

\section{Create New Dataset}
\begin{python}
from dataset import DatasetWriter
datasets = ('previous',)

def prepare():
  dw = DatasetWriter(
    hashlabel = 'X',
    previous = datasets.previous,
  )
  dw.add('X', number)
  dw.add('Y', number)
  dw.add('Z', number)
  return dw

def analysis(sliceno, prepare_res):
  dw = prepare_res
  dw.write(x, y, z)
\end{python}

\section{Appending to a Dataset}
append


% more on datasets: previous, link_to_here
  
