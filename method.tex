%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                          %
% Copyright (c) 2018 eBay Inc.                                             %
%                                                                          %
% Licensed under the Apache License, Version 2.0 (the "License");          %
% you may not use this file except in compliance with the License.         %
% You may obtain a copy of the License at                                  %
%                                                                          %
%  http://www.apache.org/licenses/LICENSE-2.0                              %
%                                                                          %
% Unless required by applicable law or agreed to in writing, software      %
% distributed under the License is distributed on an "AS IS" BASIS,        %
% WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. %
% See the License for the specific language governing permissions and      %
% limitations under the License.                                           %
%                                                                          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Methods are source files that can be executed by the Accelerator.
They may be built by a build script or by another method as a subjob.
When methods are build, i.e.\ assigned input arguments and executed,
the result is called a job.


\section{Method Directories and Method Source Files}

Methods are stored in directories, called method directories, one
level above the Accelerator directory, like this
\begin{verbatim}
project_directory
+-- accelerator
+-- method_directory  # here be methods
\end{verbatim}
For a method directory to be visible by the Accelerator, two things are needed
\begin{itemize}
\item it must be specified in the configuration file, see section~\ref{configfile}, and
\item the method directory must contain an empty file named
  \texttt{\_\_init\_\_.py}.
\end{itemize}
Furthermore, in order to avoid execution of the wrong files, there are
two limitations that apply to methods.
\begin{itemize}
\item For a method file to be accepted by the Accelerator, the filename has to start with
  the prefix ``\texttt{a\_}'', and
\item the method name, without this prefix must be present on a
  separate line in the \texttt{methods.conf} file for the package, see
  section~\ref{methods_conf}.
\end{itemize}



\section{Method Source Code Hashing}

Prior to executing a method, the Accelerator is applying a hash
function to the method source code to determine if an eqivalent job
already exists.  This hash is combined with the input arguments and
compared to all jobs already built.  Only if the hash and input
parameter combination is unique will the method be executed.

A method may import code located in other files, and these other files
can be included in the hash calculation as well.  This will ensure
that a change to an imported file will indeed force a re-execution of
the method if a build is requested.  Additional files are specified in
the method using the \texttt{depend\_extra} list, as for example:
\begin{python}
import generic_params
depend_extra = (generic_params, 'mystuff.data',)
\end{python}
It is possibe to specify either Python module objects or a filename
relative to the method's location.

A different scenario is when the method source code needs to be
modified, but the modification does not alter its behavior, so
rebuilding jobs should be actively avoided.  A simple example would be
changing the name of a variable in the method.  For this situation,
there is an \texttt{equivalent\_hashes} \texttt{dict} that can be used
to specify which versions of the source code that are equivalent.  For
example
\begin{python}
  equivalent_hashes = {'verifier': ('0c573685f713ac6500a6eda7df1a7b3f',)}
\end{python}
The verifier string is a hash that depends on everything in the method
except the equivalent\_hashes block.  When the hash value of the
method does not correspond to the verifier (as will happen after
editing the method) the Accelerator will informed what the correct
verifier would be, so it can be added to the list of verifiers if
appropriate.  The verifier list can contain any number of old hashes.

\comment{KOLLA DETTA}



\clearpage
\section{Method Parameters}

A jobs parameters are available in the \texttt{params} variable.  It
contains both input parameters that are assigned from the caller, and
parameters that are created when the job starts building.  Input
parameters will be described thoroughly in section~\ref{xx}.  Consider
the following example method that pretty-prints the \texttt{params}
variable.  Note that the method explicitly expects input parameters to
be assigned by the caller in the \jobids, \datasets, and \options
variables.

\begin{python}
import json

jobids = ('jid',)
datasets = ('source', 'parent',)
options = dict(x='testing', length=3)

def synthesis(params):
    print(json.dumps(params, indent=4))
\end{python}
And here is the corresponding output.
\begin{leftbar}
\begin{minted}{json}
{
    "link": {},
    "package": "dev",
    "method": "test2",
    "jobid": "EXAMPLE-12",
    "starttime": 1520652213.4547446,
    "params": {
        "test2": {
            "options": {
                "x": "testing",
                "length": 3
            },
            "datasets": {
                "source": "EXAMPLE-0",
                "parent": null
            },
            "jobids": {
                "jid": "EXAMPLE-0"
            }
        }
    },
    "slices": 16,
    "options": {
        "x": "testing",
        "length": 3
    },
    "datasets": {
        "source": "EXAMPLE-0",
        "parent": null
    },
    "caption": "fsm_test2",
    "seed": 53231916470152325,
    "jobids": {
        "jid": "EXAMPLE-0"
    },
    "hash": "42af401251840b3798e9e78da5b5c5b4ef525ecc"
}
\end{minted}
\end{leftbar}
and a desciption of its keys
\begin{snugshade}
\begin{tabular}{ll}
  \textsl{key} & \textsl{description}\\[2ex]\hline\\[1ex]
  \texttt{package} & method directory for this method\\
  \texttt{method} & name of this method\\
  \texttt{jobid} & jobid of this job\\
  \texttt{starttime}& start time in epoch format\\
  \texttt{params} & \\
  \texttt{slices} & number of slices of current Accelerator configuration \\
  \texttt{options} & \\
  \texttt{dataset} & \\
  \texttt{jobids} & \\
  \texttt{caption} & a caption\\
  \texttt{seed} & a random seed available for use\\
  \texttt{hash} & current source code hash value\\
\end{tabular}
\end{snugshade}



\section{Input Parameters}
A method is typically provided with input parameters at build time.
There are three kinds of method input parameters: \jobids, \datasets,
and \options.  These parameters are specified early in the method
source code, such as for example
\begin{python}
jobids = ('accumulated_costs',)
datasets = ('transaction_log', 'access_log',)
options = dict(length=4)
\end{python}
The \texttt{jobids} parameter list is used to input links, or jobids,
to other jobs, while the \datasets parameter list is used to input
links to datasets. The \options dictionary is used to input any other
type of parameters to be used by the method at run time.  Note that
\jobids and \datasets are tuples (and a single entry has to be
followed by a comma as in the example abov), while \options is a
dictionary.  Each of these parameters will be described in more detail
in following sections.

Individual elements of the input parameters may be accessed with dot
notation like this
\begin{python}
jobids.accumulated_cost
datasets.transaction_log
options.length
\end{python}



\subsection*{Jobids}
The \jobids parameter is a tuple of jobids linking this job to other
jobs.  Inside the running method, each item in the \jobids tuple may
be used as a reference to the corresponding job.

\comment{SHOULD WE ALLOW EMPTY JOBIDS?}



\subsection*{Input Datasets}
The \datasets argument is the way to communicate datasets from
automata to job.  In the running method, the \datasets variable is a
tuple of objects from the dataset class.  The dataset class is
described in a dedicated chapter~\ref{xx}.

All items in the \datasets tuple must be assigned by the builder to
avoid run time errors.

\comment{BUT WE NEED TO BE ABLE TO INDICATE START OF CHAIN, FOR EXAMPLE BY None.}



\subsection*{Input Options}

The \options parameter is of type \texttt{dict} and used to pass
various information from the builder to a job.  This information could
be integers, strings, enumerations, sets, lists, and dicts in a
recursive fashion.  Options may have a default value.

Options are defined in a method like this
\begin{python}
  options = dict(key=value, ... )  # or
  options = {key: value, ...}
\end{python}

Options are quite advanced, and the following sections introduce how
to use them both from a formal perspective, and from a set of
examples.

\subsubsection{Formal Option Rules}
The \options parameter is vey flexible.  These are the formal rules
for specifuing options.
\begin{itemize}

\item Typing may be specified using the class name (i.e.\ \texttt{int}), or as
  a value that will construct into such a class object (i.e.\ the
  number 3).  See this example
  \begin{python}
options = dict(
    a = 3,     # typed to int
    b = int,   #          int
    c = 3.14,  #          float
    d = '',    #          str
)
  \end{python}
  but read on to learn about default values and more.

 \item An input option value is required to be of the correct type.  This is,
  if a type is specified for an option, this must be respected by the
  builder.

\item An input may be left unassigned, unless
  \begin{itemize}
  \item the option is typed to \mintinline{python}/RequiredOptions()/, or
  \item the option is typed to \mintinline{python}/OptionEnum()/ without a default.
  \end{itemize}
  So, except for the two cases above, it is not necessary to supply
  option values to a method at build time.

\item If typing is specified as a value, this is the default value if
  left unspecified.

\item If typing is specified as a class name, default is None.

\item Values are accepted if they are valid input to the type's
  constructor, i.e.\ 3 and '3' are valid input for an integer.

\item None is always a valid input unless
  \begin{itemize}
  \item RequiredOptions() and not none\_ok set
  \item OptionEnum() and not none\_ok set
  \end{itemize}
  This means that for example something typed to \texttt{int} can be
  overridden by the builder by assigning it to
  \mintinline{python}/None/.

\item All containers can be specified as empty \comment{(?)}

\item Complex types (like \texttt{dict}s, \texttt{dict}s of
  \texttt{list}s of \texttt{dict}s, \dots) never enforce specific
  keys, only types.  For example, \mintinline{python}/{'a': 'b'}/ is a
  valid value for \mintinline{python}/{'foo': 'bar'}/. \comment{(?)}

\item Containers with a type in the values default to empty containers.
  Otherwise the specified values are the default contents.  Example
  \begin{python}
options = dict(
    x = dict,           # will be empty dict as default
    y = {'foo': 'bar'}  # wil be {'foo': 'bar'} as default
)
  \end{python}
\end{itemize}
%%%
%%%

Typing and default values are presented in the following sections.
Default values are assigned if there is no input.  Note that
definition of type is that the constructor must accept the value
provided, for example the string \texttt{'3'} is a valid input for the
\texttt{int} constructor.


\subsubsection{Unspecifieds}
An option with no typing may be specified by assigning \texttt{None}.
\begin{python}
options = dict(length=None)  # accepts anything, default is None
\end{python}
Here, \texttt{length} could be set to anything.



\subsubsection*{Scalars}
Scalars are either explicitly typed, as
\begin{python}
options = dict(length=int)   # Requires an intable value or None
\end{python}
or implicitly with default value like
\begin{python}
options = dict(length=3)     # Requires an intable value or None,
                             # default is 3 if left unassigned
\end{python}
In these examples, intable means that the value provided should be
valid input to the \texttt{int} constructor, for example the number~3
or the string \texttt{'3'} both yield the integer number 3.



\subsubsection*{Strings}
A (possibly empty) string with default value \mintinline{python}{None} is typed as
\begin{python}
options = dict(name=str)     # requires string or None, defaults to None
\end{python}
A default value may be specified as follows
\begin{python}
options = dict(name='foo')   # requires string or None, provides default value
\end{python}
And a string required to be specified and none-empty as
\begin{python}
from extras import OptionString
options = dict(name=OptionString)       # requires non-empty string
\end{python}
In some situations, an example string is convenient
\begin{python}
from extras import OptionString
options = dict(name=OptionString('bar') # Requires non-empty string,
                                        # provides example (NOT default value)

\end{python}
Note that ``textt{bar}'' is not default, it just gives the programmer
a way to express what is expected.



\subsubsection*{Enums}
Enumerations are convenient in a number of situations.  An option with
three enumerations is typed as
\begin{python}
# Requires one of the strings 'a', 'b' or 'c'
from extras import OptionEnum
options = dict(foo=OptionEnum('a b c'))
\end{python}
and there is a flag to have it accept \mintinline{python}/None/ too
\begin{python}
# Requires one of the strings 'a', 'b', or 'c'; or None
from extras import OptionEnum
options = dict(foo=OptionEnum('a b c', none_ok=True))
\end{python}
A default value may be specified like this
\begin{python}
# Requires one of the strings 'a', 'b' or 'c', defaults to 'b'
from extras import OptionEnum
options = dict(foo=OptionEnum('a b c').b
\end{python}
(The \texttt{none\_ok} flag may be combined with a default value.)
Furthermore, the asterisk-wildcard could be used to accept a wide
range of inputs
\begin{python}
# Requires one of the strings 'a', 'b', or any string starting with 'c'
options = dict(foo=OptionEnum('a b c*'))
\end{python}
\comment{reformulate.  How is it an enum when num inputs is unknown?}



\subsubsection*{Lists and Sets}
Lists are specified like this
\begin{python}
# Requires list of intable or None, defaults to empty list
options=dict(foo=[int])
\end{python}
\comment{also accepts empty list}
and sets are defined similarly
\begin{python}
# Requires set of intable or None, defaults to empty set
options=dict(foo={int})
\end{python}
Note that in both cases, both \mintinline{python}/None/ and an empty
list/set is valid input.


\subsubsection*{More complex stuff}
It is possible to have more complex types, such as dictionaries of
dictionaries and so on, for example
\begin{python}
# Requires dict of string to string
options = dict(foo={str: str})
\end{python}
or another example
\begin{python}
# Requires dict of string to dict of string to int
options = dict(foo={str: {str: int}})
\end{python}
As always, containers with a type in the values default to empty
containers.  Otherwise, the specified values are the default contents.



\subsubsection*{Date and Time}
The following date and time related types are supported:
\begin{itemize}
\item[] \texttt{datetime},
\item[] \texttt{date},
\item[] \texttt{time}, and
\item[] \texttt{timedelta}.
\end{itemize}
A typical usecase is as follows
\begin{python}
# a datetime object if input, or None
from datetime import datetime
options = dict(ts=datetime)
\end{python}
and with a default assignment
\begin{python}
#  a datetime object if input, defaults to a datetime(2014, 1, 1) object
from datetime import datetime
options = dict(ts=datetime(2014, 1, 1))
\end{python}



\subsubsection*{JobWithFile}
Any file residing in a jobdir may be input to a method like this
\begin{python}
from extras import JobWithFile
options = dict(usefile=JobWithFile(jid, 'user.txt')
\end{python}
There are two additional arguments, \texttt{sliced} and
\texttt{extras}.  The \texttt{extras} argument is used to pass any
information that is helpful when using the specified file, and
\texttt{sliced} tells that the file is stored in parallel slices.
\begin{python}
options = dict(usefile=JobWithFile(jid, 'user.txt', sliced=True, extras={'uid': 37}))
\end{python}
In the method, the \texttt{JobWithFile} object has these members
\begin{python}
usefile.jobid
usefile.filename
usefile.sliced
usefile.extras
\end{python}
Where the full filename of the file is available through
\begin{python}
from extras import full_filename
print(full_filename(filename, ''))
\end{python}
The second option to \texttt{full\_filename} is mandatory, it may be
empty as in the example above, and should hold the filename extension.
\comment{Will be changed?!}
\comment{Example of how to use jobwithfile in analysis and prepare/synthesis.  how does slice work?  How does extras work?}



\subsection{Accessing Another Job's \params using \jobparams}

The previous sections show that the the \params data structure
contains all input parameters and initialization data for a job.
Sometimes it is useful to access another job's \params.  There is a
special function for that, called \texttt{job\_params}, and it is used
like this
\begin{python}
from extras import job_params

jobids = ('anotherjob',)

def synthesis():
    print(jobids.anotherjob)
    # will print something like 'jid-0_0'
    print(job_params(jobids.anotherjob).options)
    # will print the options of anotherjob, perhaps something like {length: 3}
\end{python}

\comment{if we ``objectify'' options, we could just do jobids.anotherjob.params}



\newpage
\section{Code Flow:  \prepare, \analysis, and \synthesis}

There are three pre-defined functions in a method, \prepare,
\analysis, and \synthesis, and they are always run in that order.
\prepare and \synthesis are single threaded, while \analysis provides
parallel execution.

The following combinations are valid and are of practical use
\begin{itemize}
\item \synthesis-only, used for a single threaded program
\item \analysis-only, used for completely parallel tasks
\item \prepare + \analysis, setup and run a parallel job
\item \analysis + \synthesis, run a parallel job and combine outputs
\item \prepare + \analysis + \synthesis, setup, run, and combine a
  parallel task.
\end{itemize}
All the three functions take \options, \jobids, and \datasets as
optional arguments.  The \analysis function takes a required argument
\texttt{sliceno}, which is an integer between zero and the total
number of slices minus one.  This is the unique identity indicator for
the \analysis process.

Return values may be passed from one function to another.  What is
returned from prepare is called \prepareres, and may be used as input
argument to \analysis and \synthesis.  The return values from
\analysis is available as \analysisres in \synthesis.  The return
value from \synthesis is stored permanently in the jobdir.  A complete
example may look like
\begin{python}
options = dict(length=4)
datasets = ('transaction_log')

def prepare(options):
  return options.length * 2

def analysis(sliceno, prepare_res):
  return set(
    u for u in datasets.transaction_log.iterate(sliceno, 'user')
  )

def synthesis(analysis_res, prepare_res):
   return analyses_res.merge_auto()
\end{python}


\subsection{The \params Variable }
The \params variable contain all input and initialization parameters
for a job, such as the caption
\begin{python}
def synthesis(params):
  print params.caption
# urd_dispatched_method1
\end{python}
The \params variable contains lots of information that is typically
not required in a regular method.  For a method developer, the most
important members are
\begin{python}
params.package     # which package the method source code is stored in
params.slices      # number of slices for the workdirs in use
params.caption     # may be specified when building a job
params.seed        # seed to initialize a random number generator
params.starttime   # execution start in epoch time
\end{python}
but params does also contain all options, jobids, and datasets inputs.







\newpage
\section{More on Intermediate and Result Files}

\subsection{Sharing Data Inside a Job}
Data is easily shared between \prepare, \analysis, and \synthesis as
follows.
\begin{itemize}
\item what is returned in \prepare is available as \prepareres in \analysis and \synthesis
\item what is returned in \analysis is available as \analysisres in \synthesis.  \analysisres is an iterator.
\item what is returned in \synthesis is a persistent file in the job catalog referenced by \texttt{result}.
\end{itemize}

\subsubsection*{The blob module}
The simplest way to share intra job data is using the blob module.
\begin{python}
import blob
def synthesis()
  blob.load('filename')
\end{python}
saving data is as follows
\begin{python}
  blob.save(data, filename, sliceno=None, temp=None)
\end{python}
\sliceno and \texttt{temp} are optional.  If \sliceno is set, data is
stored in a sliced file.  This is typically used in \analysis, where
each thread will save its own file.  The argument \texttt{temp} is
used for file persistence.  By default, files are stored permanently
when a job terminates successfully.  Setting \texttt{temp} to
\texttt{True} removes them upon completion of the job.  Temporary
files are useful when communicating data between the functions in the
method (and not using the res-files) or in debugging.


\subsection{debug help}
There is also a more advanced debug functionality relating to temp.
\begin{python}
from extras import Temp
def analysis(sliceno):
  ...
  blob.save(data, filename, sliceno=sliceno, temp=Temp.DEBUG)
  # or
  blob.save(data, filename, sliceno=sliceno, temp=Temp.DEBUGTEMP)
\end{python}
where the first only stores when \texttt{--debug} is specified, and
the other always stores but removes unless \texttt{--debug} is set.


\newpage
\section{Subjobs}

Jobs may launch subjobs.  If the jobs are already built, they will be
immediately linked in.  The syntax is as follows, assuming we build
the jobs in\prepare:
\begin{python}
import subjobs

def prepare():
  subjobs.build('count_items', options=dict(length=3))
\end{python}
The \texttt{subjobs.build} uses the same syntax as \texttt{urd.build}
described elsewhere, so \options, \datasets, \jobids, and
\texttt{caption} are available.  Similarly, subjob jobid is returned.

If there are datasets built in a subjob, these will not be explicitly
available to Urd.  Instead, the dataset definition may be copied to
the launching method like this
\begin{python}
from Dataset import dataset

def synthesis():
  jid = subjobs.build('create_dataset')
  Dataset(jid).link_to_here(name='thename')
\end{python}
the \texttt{name} argument is optional, the name \texttt{default} is
used if left empty, corresponding to the default dataset.

Currently there is no dependency checking on subjobs, so if a subjob
method is changed, the calling method will not be updated.  The
current remedy is to use \texttt{depend\_extra} in the callin method,
like this
\begin{python}
import subjobs

depend_extra = ('a_childjob.py',)

def prepare():
  subjobs.build('childjob')
\end{python}
